# 目的
13clues というゲームの戦略について考えたりする。

## ゲームの概要
13clues のゲームの概要を軽く一般化しつつ、簡単にしつつ話す
- ゲームの前提条件
    - プレイヤーは2以上の人数がいればよい。
        - つまり、3人以上で行うことがある。
    - カードと呼ばれるものを扱う。
    - カードはそれぞれ属性を持つ。
        - どんな属性があるかは事前に明かされている。
        - カードは属性を複数持ちうる。
- ゲーム開始時
    - 各プレイヤーは、手元に何枚か頭に何枚かのカードを、かぶりなく、ランダムに与えられる。
    - 使うカードは全体のカードの全部でなくてもよい。
    - 自分の手元にあるカードは自分だけが見ることができる。
    - 自分の頭にあるカードは自分では見ることができず、他の全てのプレイヤーは見ることができる。
        - つまり、あるプレイヤーからは自分の手札と他のプレイヤーの頭にあるカードのみを見ることができるが、これを **そのプレイヤーから見えるカード** と呼ぶ。
- プレイヤーの手番
    - 各プレイヤーは順番に行動を行う。（順番についてはどうでもいい。）行動は2種類ある。
    1. 他のプレイヤーに、そのプレイヤーから見えるカードの中に、ある属性を持つカードが何枚含まれているかを聞くことができる。
        - 聞いた結果は全てのプレイヤーに共有される。
    2. ２つ目は、自分の頭にあるカードが何かを宣言する。
        - あっている場合は勝利し、あっていない場合はそのままゲームが続く。
        - 宣言の内容とその結果は全てのプレイヤーに共有される。
    - 同じ行動を二回以上行うことはできない（ゲームの推移が必ず有限になるようにしたい。）
- 勝利条件について
    - プレイヤーの勝利条件は、「行動2で自分の頭にあるカードを言い当てたとき」になる。
    - 他のプレイヤーが勝利した時点でそのゲームは終了し、勝者は一人である。

# とりあえず途中まで形式化
## ゲームの設定部分（パラメータ）
- プレイヤーの人数 （$n$） ... $n \in \mathbb{N}_{\geq 2}$
- カードの全体（$X$） ... $X: \text{finite Set}$
- 属性の全体（$S$） ... $S: \text{finite Set}$
- 各カード $x \in X$ に対してその属性を表す部分集合（$s_x$） ... $s_x \subset S$
- 頭と手元に何枚配られるか（$l$, $m$） ... $l \in \mathbb{N}$ 枚と、手元に $m \in \mathbb{N}$ 枚
- カードの配り方（$D$） ... $X = H^{\text{head}}_1 \sqcup \cdots \sqcup H^{\text{head}}_n \sqcup H^{\text{hand}}_1 \sqcup \cdots \sqcup H^{\text{hand}}_n$ であって $\# H^{\text{head}}_{*} = l, \# H^{\text{hand}}_{*} = m$ を満たすもののこと

## 定義部分
- プレイヤー $i$ が他のプレイヤー $j$ に対して属性 $s \in S$ の見える枚数を聞く質問（$M^{\text{Q}}_i$）:= $\{(j, s) \in \{1..=n\} \times S \mid i \neq j\}$
- $\rightarrow$ 回答（$A^{\text{Q}}$）: $D \times M^{\text{Q}}_i \to \mathbb{N}$ := $\# ((H, (j, s)) \mapsto H^{\text{hand}}_i \cup \bigcup_{k \neq j} H^{\text{head}}_k)$
- プレイヤー $i$ が頭のカードが $X' \subset X$ であることを宣言する （$M^{\text{D}}_i$） := $\mathcal{P}(X)$
- $\rightarrow$ 回答（$A^{\text{D}}$）: $D \times M^{\text{D}}_i \to \text{bool} = \{\text{true}, \text{false}\} := (H, X') \mapsto H^{\text{head}}_i == X'$

- ゲームの推移は次のもので記述できる。
- 一番初めの状態 ... $H \in D$
- 質問と回答の組の有限列 ... $m_1, \ldots, m_k$ で次を満たすもの
    - $m_l \in M_{l \bmod n}^{\text{Q}} \cup M_{l \bmod n}^{\text{D}}$ （ $l$ ターンでのプレイヤーのとれる行動
    - $m_{l_1}, m_{l_2}$ で $l_1 \equiv l_2 \mod n$ なら $m_{l_1} \neq m_{l_2}$

ゲーム木の述べ方やゲームの定式化が難しい。
特に、各プレイヤーから見ることができる情報が完全でないことなどのせい？
いくつか例を見る。

# ゲームの例
## 戦略ゲームの場合
せーので戦略を選んで一斉に利益を得る場合、戦略の集合と選択して何が得られるかがわかればいい。
- プレイする人数（$n$）: $\mathbb{N}$
- 戦略の全体（$\Sigma_i$）: $\text{Set}$
- 功利関数： $\Pi_{i \in \{1..=n\}} \Sigma_i \to \mathbb{R}^n$

## 完全情報ゲームの場合
### 適当な定式化
- ゲームの状態をなんらかの集合 $X$ で表す
- 一番初めの初期状態 がある
- 各状態ごとに、どのプレイヤーが行動できるか、どんな行動ができるかが決まっている：
- そこに到達するとゲームが終了する状態がある。
- 終了状態では行動を起こせない。
- 終了状態に到達すると、各プレイヤーはその終了状態に応じた点数が得られる。
### ゲーム部分
- プレイヤーの人数 ... $n$: $\mathbb{N}
- 状態の全体...$X$: $\text{Set}$
- 初期状態...$x_0$: $X$
- 各状態ごとにどのプレイヤーが行動をするか...$P$: $X \rightarrow \{1..=n\}$
- 各状態からどんな行動ができるか... $M$: $X \rightarrow \mathcal{P}(X)$
    - $M(x)$ からプレイヤーはゲームをどの状態にとるかを選べるということ。
- 終了状態 ... $S$: $\mathcal{P}(X)$
    - 終了状態では行動が起こせない...$s \in S \implies M_s = \emptyset$
    - 終了状態ごとにプレイヤーの得られる点数: $p = (p_1, \ldots, p_n):S \rightarrow \mathbb{R}^n$ で $p_i$ がプレイヤー $i$ のえられる点数である。
### ゲームの戦略の定義
ゲームの進行状況は $X$ の有限列 $(x_0, x_1, \ldots, x_k)$ であって $x_{i+1} \in M_{x_i}$ となるもののであらわされる。
戦略とは、進行状況をもとにどう動くかを決めるもののこと。

- 考えうる戦略の分け方は２種類ある。
    - 決定的であるか（純粋戦略）、確率的であるか（混合戦略）：$ x$ でとることのできる行動 $M_x$ に対して、 $M_x$ 上の元を返すか、確率分布を返すか
    - 決め打ち的であるか進行状況を見るか： 与えられた $x \in X$ だけをもとに行動を選択するか、ゲームの進行状況 $(x_0, x_1, \ldots, x_k)$ をも行動の選択に用いるか
- プレイヤー $i$ のとる、状態に対して決め打ち的で決定的な戦略：
    - 自分が行動しなければいけない状態（ $ x \in X$ であって $P_x = i$ となるもの全体）に対して、
    - そこでどんな行動をとるか（ $ x' \in M_x$ の元）を決めることになる。
    - つまり、 $\sigma: \{x \in X \mid P_x = i \} \rightarrow X$ であって $\sigma(x) \in M_x$ を決めることが戦略を決めること。
- プレイヤー $i$ のとる、進行状況に依存した決定的な戦略：
    - 各進行状況 $(x_0, x_1, \ldots, x_k)$ であって $P_{x_k} = i$ となるものに対して $M_{x_n}$ の元を返すものを定めること。
- 確率的な戦略（混合戦略というらしい）の場合：
    - 行動しなければいけない状態  $ x \in X$ で可能な行動全体 $ M_x$ に確率を割り当てることになる。
    - 決め打ち戦略なら $\sigma : (x: \{x \in X \mid P_x = i\}) \rightarrow M_x \rightarrow \mathbb{R}_{\geq 0}$ であっ次を満たすもののことが戦略。
        - $\forall x. \sum_{y \in M_x} \sigma(x)(y) = 1$
    - 進行状況を見るにしても同じようなもの。

### 戦略から得られる期待値の計算・"最適"な戦略が定義できるか：
- 純粋戦略を全員が決め打ちする場合を考える。
    - プレイヤー $i$ のとる戦略を $\sigma_i$ とする。
    - ゲームの進行は決定的である： $ (x_0, x_1, \ldots, x_k)$ であって、 $x_{i+1} = \sigma_{P_{i}}(x_i)$ となるもののみがゲームの進行状況となる。
    - 一般のゲームでは終わらないことがある。
        - 「もし終わらなかった場合にはそれぞれのプレイヤーに $p$ 点をあげる」とすることで、全てのゲームが終わると仮定してもよい。
        - （終わらなかった場合に $ -\infty$ をあげるとすることで終わらせる動機になり、 $\infty$ をあげるとすれば絶対に終わらせない動機になる、調整をここでやれる。）
    - よって、各プレイヤー $i$ の取ることができる戦略全体を $ \mathcal{S}_i$ とすると、 $ \mathcal{S}_1 \times \cdots \times \mathcal{S}_n \rightarrow \mathbb{R}^n \cup \{- \infty, \infty\}$ が計算できる。
    - これは戦略ゲームに還元できたことになるので、ゲーム理論の範疇であり、ナッシュ均衡（？）とかが存在する、ので解けている。
        - ただし、ナッシュ均衡が計算できるかは別である。
- 純粋戦略で進行状況に依存する場合：
    - この場合も進行状況は決定的なので上と同じことができる。
- 混合戦略の場合：
    - 可能なゲームの進行状況全体を考えるとき、「終了状態だけを使って確率を考える」か「終了しない過程も考える」かで計算の方法が変わってきそう。
    - 無限集合の確率とか和をとることになるのでつらい（測度論？）

#### 注意点
- 普通はゲームといえば木だがその定義を含んでいる。この場合、決め打ち戦略と進行状況依存戦略は同じである。
- 状態が有限で木になっているのであれば、ゲームは必ず終わる。
- ここでは、ゲームがどの状態にあるかを各プレイヤーが知っている（＝完全情報なゲームである）という前提が、プレイヤーの取る行動を $X \rightarrow \mathcal{P}(X)$ として表せるということに落とし込まれている。
    - つまり、プレイヤーはゲームの状態が今どれなのかをもとに行動してよい。
- また、手番と進行状況をゲームの状態に導入すれば明らかにゲーム木に変形することができ、その場合、「進行状況に依存する戦略」を「決め打ち的な戦略」に変形することができる
- ところどころで、無限集合の上で確率を考えているので、数学的にはやばい操作がたくさんある。
    - 例えば、 $M_x$ が有限でないと $\Sigma_{y \in M_x} \sigma(x)(y)$ はうまくふるまわない。
- 混合戦略に対して得られる点数の期待値を考えるのは難しい。

## 不完全情報のゲームの場合
### 適当な定式化（完全情報と比べたとき）
- プレイヤーに対してゲームがどの状態にあるのかが明かされていない
    - つまり、プレイヤーからは識別できないノードの全体がある。
    - 終了状態にいることは識別できてどの終了状態にいるのかも識別できる、当然そこからは行動ができない。
### ゲーム部分
- ゲームの状態 $X$, 終了状態 $S \subset X$, 終了状態で得られる点数 $p: S \rightarrow \mathbb{R}^n$ は変わらない。
- プレイヤーからは識別できない状態への分割...ある添え字集合 $\Lambda$ を用いて $X = \bigsqcup_{\lambda \in \Lambda} X_{\lambda}$
- $x \in X$ に対して $ \lambda(x) := \lambda \in \Lambda$ s.t. $ x \in X_{\lambda}$ とする
- ゲームが終了する場合は識別が一意にできるとする ... $ s \in S \implies \# X_{\lambda(s)} = 1$
- 可能な初期状態 ... $X_0 \subset X$ ただし、 $0 \in \Lambda$
- 各 $\lambda \in \Lambda$ で行動するプレイヤー ... $ \Lambda \rightarrow \{1 ..= n\}$
- 各 $\lambda \in \Lambda$ でとることのできる行動一覧 ... $ M_\lambda$
    - ただし終了状態からは行動できない... $s \in S$ なら $M_{\lambda(s)} = \emptyset$
- その行動によるゲームの推移 ... $ M: X_{\lambda} \times M_{\lambda} \rightarrow X$
#### 注意点
- 異なるプレイヤーで得られる情報が異なるゲームの場合に、 $\lambda \in \Lambda$ への分割というのがその点をうまく表せていないように思えるが、これは戦略の定義でゲームの推移をプレイヤーが知ることができないと定めることで回避できる。
    - （というか、"プレイヤーが知ることのできる情報"を全部 [$ \lambda$ に入れてしまう。）
    - まあ各プレイヤーからみた区別できなさをゲームの中に定式化してもいいけど。
### ゲームの分析
- ゲームの進行状況は $X$ の有限列 $(x_0, m_0, m_1, \ldots, m_k)$ であって $x_0 \in X_0$ かつ $m_i \in M_{x_i}, x_{i+1} = M(x_i, m_i)$ で表せる。
- ただし、 $X_{\lambda \in \Lambda}$ で行動するプレイヤー $P_{\lambda}$ は現在の $\lambda \in \Lambda$ というラベルのみ情報を得られるものとする。
- 戦略は完全情報でいうところの決め打ち戦略しかない。
- プレイヤー $i$ の純粋戦略とは $\sigma$: $\{\lambda \in \Lambda \mid P_{\lambda} = i\} \rightarrow M_{\lambda}$ のこと
- 混合戦略とは $\sigma$: $\{\lambda \in \Lambda \mid P_{\lambda} = i\} \rightarrow M_{\lambda} \rightarrow \mathbb{R}_{\geq 0}$ であって sum のいい条件を満たすもののこと。

## これらの定式化の問題点？
ゲーム理論では、Query のようなものをうまく定式化しにくい：
- プレイヤーの取る手として Query と Answer の組を書くのはゲームがうまく表せていないので不適で、 Query を行った後に Answer に応じて状態を（自動的に）移る仕組みが必要？
    - GMの導入をすればよい。

## 13 clues に戻る
"全探索"の意味がわからないのが問題だった。
- 不完全情報ゲームとしては 13 clues は定式化できそう。
- また、戦略も定義できそう。
- ある戦略が最適であるとは？
- 全探索をするとは？
